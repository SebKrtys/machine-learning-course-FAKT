{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2e0ac9",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159b1e4",
   "metadata": {},
   "source": [
    "First, I started with a neural network model, where I got the best prediction as of 52%. After having a chat with Frigyes in the Heller dormatory, I turned towards boosting. According to ChatGPT, I chose extreme gradient boosting, the results are presented below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b9a94",
   "metadata": {},
   "source": [
    "### Predicting binary outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32293852",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.35647\n",
      "[1]\tvalidation_0-logloss:0.34536\n",
      "[2]\tvalidation_0-logloss:0.33892\n",
      "[3]\tvalidation_0-logloss:0.33595\n",
      "[4]\tvalidation_0-logloss:0.33285\n",
      "[5]\tvalidation_0-logloss:0.33149\n",
      "[6]\tvalidation_0-logloss:0.33004\n",
      "[7]\tvalidation_0-logloss:0.32925\n",
      "[8]\tvalidation_0-logloss:0.32889\n",
      "[9]\tvalidation_0-logloss:0.32843\n",
      "[10]\tvalidation_0-logloss:0.32805\n",
      "[11]\tvalidation_0-logloss:0.32780\n",
      "[12]\tvalidation_0-logloss:0.32853\n",
      "[13]\tvalidation_0-logloss:0.32902\n",
      "[14]\tvalidation_0-logloss:0.32988\n",
      "[15]\tvalidation_0-logloss:0.33001\n",
      "[16]\tvalidation_0-logloss:0.32990\n",
      "[17]\tvalidation_0-logloss:0.33023\n",
      "[18]\tvalidation_0-logloss:0.33077\n",
      "[19]\tvalidation_0-logloss:0.33089\n",
      "[20]\tvalidation_0-logloss:0.33171\n",
      "[21]\tvalidation_0-logloss:0.33200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load data\n",
    "test = pd.read_csv('D:\\\\Corvinus\\\\23_24_1\\\\ML\\\\test.csv')\n",
    "train = pd.read_csv('D:\\\\Corvinus\\\\23_24_1\\\\ML\\\\train.csv')\n",
    "\n",
    "# Prepare data\n",
    "X_train = train.iloc[:, :59]\n",
    "y_train = train.iloc[:, 59]\n",
    "X_test = test.iloc[:, :59]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_scaled, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,  # To avoid a warning message in newer versions\n",
    "    early_stopping_rounds=10  # Stop training if no improvement in 10 rounds\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_split, y_train_split,\n",
    "    eval_set=[(X_val_split, y_val_split)]\n",
    ")\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Create a DataFrame for final scores\n",
    "FinalScores = pd.DataFrame({'article_id': test.iloc[:, 59].astype('int32'), 'score': y_pred.astype('int32')})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "FinalScores.to_csv('XGBoost_output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa55b2e",
   "metadata": {},
   "source": [
    "First I tried to predict the binary variable, but it gave quite poor results, so I moved to predicting classification probabilities. The train-validation split and the model parameters are from ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f4a7d",
   "metadata": {},
   "source": [
    "### Predicting probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "078180a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]  # Probability of the positive class\n",
    "\n",
    "# Create a DataFrame for final scores\n",
    "FinalScores = pd.DataFrame({'article_id': test.iloc[:, 59].astype('int32'), 'score': y_pred_proba})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "FinalScores.to_csv('XGBoost_output_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e3f5e",
   "metadata": {},
   "source": [
    "By predicting probabilities, the performance of the model improved significantly, and thanks to the developers the xgboost package it could be easily implemented. Next, I applied hyperparameter optimization to ameliorate the predictive power of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffad32b",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a4e75d",
   "metadata": {},
   "source": [
    "To do so, I defined 4x3 parameter grid, where I vary the learning rate of the model, the maximum depth of decision trees, the number of estimators and the percentage of features to be used for building a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f038d0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=200; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=200; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=200; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=200; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=200; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=200; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200; total time=   2.6s\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False)\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_log_loss',  # Use log loss as the scoring metric for binary classification\n",
    "    cv=3,  # Number of cross-validation folds\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, **best_params)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]  # Probability of the positive class\n",
    "\n",
    "# Create a DataFrame for final scores\n",
    "FinalScores = pd.DataFrame({'article_id': test.iloc[:, 59].astype('int32'), 'score': y_pred_proba})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "FinalScores.to_csv('XGBoost_output_proba_tuned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cecd2bcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaef149",
   "metadata": {},
   "source": [
    "Hyperparameter tuning improved the model further, and the best model can be achieved, when the parameters are the following: 80% of the features are used to create each tree, the learning rate is 10%, the maximum depth of the decision trees is 3, and the optimal number of estimators is 100.\n",
    "Thinking about other ways to build a better model, regularization came to my mind. Again, the great work of the xgboost developers made it very easy to implement. The regularization parameters are from ChatGPT again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7134d",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6ba14b0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.36670\n",
      "[1]\tvalidation_0-logloss:0.36184\n",
      "[2]\tvalidation_0-logloss:0.35760\n",
      "[3]\tvalidation_0-logloss:0.35399\n",
      "[4]\tvalidation_0-logloss:0.35091\n",
      "[5]\tvalidation_0-logloss:0.34820\n",
      "[6]\tvalidation_0-logloss:0.34596\n",
      "[7]\tvalidation_0-logloss:0.34406\n",
      "[8]\tvalidation_0-logloss:0.34211\n",
      "[9]\tvalidation_0-logloss:0.34057\n",
      "[10]\tvalidation_0-logloss:0.33929\n",
      "[11]\tvalidation_0-logloss:0.33816\n",
      "[12]\tvalidation_0-logloss:0.33700\n",
      "[13]\tvalidation_0-logloss:0.33618\n",
      "[14]\tvalidation_0-logloss:0.33503\n",
      "[15]\tvalidation_0-logloss:0.33430\n",
      "[16]\tvalidation_0-logloss:0.33344\n",
      "[17]\tvalidation_0-logloss:0.33276\n",
      "[18]\tvalidation_0-logloss:0.33200\n",
      "[19]\tvalidation_0-logloss:0.33149\n",
      "[20]\tvalidation_0-logloss:0.33101\n",
      "[21]\tvalidation_0-logloss:0.33061\n",
      "[22]\tvalidation_0-logloss:0.33005\n",
      "[23]\tvalidation_0-logloss:0.32958\n",
      "[24]\tvalidation_0-logloss:0.32923\n",
      "[25]\tvalidation_0-logloss:0.32898\n",
      "[26]\tvalidation_0-logloss:0.32871\n",
      "[27]\tvalidation_0-logloss:0.32852\n",
      "[28]\tvalidation_0-logloss:0.32825\n",
      "[29]\tvalidation_0-logloss:0.32805\n",
      "[30]\tvalidation_0-logloss:0.32767\n",
      "[31]\tvalidation_0-logloss:0.32745\n",
      "[32]\tvalidation_0-logloss:0.32721\n",
      "[33]\tvalidation_0-logloss:0.32712\n",
      "[34]\tvalidation_0-logloss:0.32706\n",
      "[35]\tvalidation_0-logloss:0.32669\n",
      "[36]\tvalidation_0-logloss:0.32651\n",
      "[37]\tvalidation_0-logloss:0.32632\n",
      "[38]\tvalidation_0-logloss:0.32617\n",
      "[39]\tvalidation_0-logloss:0.32602\n",
      "[40]\tvalidation_0-logloss:0.32590\n",
      "[41]\tvalidation_0-logloss:0.32568\n",
      "[42]\tvalidation_0-logloss:0.32548\n",
      "[43]\tvalidation_0-logloss:0.32527\n",
      "[44]\tvalidation_0-logloss:0.32511\n",
      "[45]\tvalidation_0-logloss:0.32503\n",
      "[46]\tvalidation_0-logloss:0.32502\n",
      "[47]\tvalidation_0-logloss:0.32487\n",
      "[48]\tvalidation_0-logloss:0.32479\n",
      "[49]\tvalidation_0-logloss:0.32456\n",
      "[50]\tvalidation_0-logloss:0.32438\n",
      "[51]\tvalidation_0-logloss:0.32437\n",
      "[52]\tvalidation_0-logloss:0.32431\n",
      "[53]\tvalidation_0-logloss:0.32413\n",
      "[54]\tvalidation_0-logloss:0.32406\n",
      "[55]\tvalidation_0-logloss:0.32382\n",
      "[56]\tvalidation_0-logloss:0.32374\n",
      "[57]\tvalidation_0-logloss:0.32362\n",
      "[58]\tvalidation_0-logloss:0.32363\n",
      "[59]\tvalidation_0-logloss:0.32363\n",
      "[60]\tvalidation_0-logloss:0.32348\n",
      "[61]\tvalidation_0-logloss:0.32344\n",
      "[62]\tvalidation_0-logloss:0.32332\n",
      "[63]\tvalidation_0-logloss:0.32331\n",
      "[64]\tvalidation_0-logloss:0.32335\n",
      "[65]\tvalidation_0-logloss:0.32343\n",
      "[66]\tvalidation_0-logloss:0.32330\n",
      "[67]\tvalidation_0-logloss:0.32329\n",
      "[68]\tvalidation_0-logloss:0.32324\n",
      "[69]\tvalidation_0-logloss:0.32312\n",
      "[70]\tvalidation_0-logloss:0.32298\n",
      "[71]\tvalidation_0-logloss:0.32294\n",
      "[72]\tvalidation_0-logloss:0.32278\n",
      "[73]\tvalidation_0-logloss:0.32281\n",
      "[74]\tvalidation_0-logloss:0.32281\n",
      "[75]\tvalidation_0-logloss:0.32277\n",
      "[76]\tvalidation_0-logloss:0.32273\n",
      "[77]\tvalidation_0-logloss:0.32278\n",
      "[78]\tvalidation_0-logloss:0.32270\n",
      "[79]\tvalidation_0-logloss:0.32272\n",
      "[80]\tvalidation_0-logloss:0.32260\n",
      "[81]\tvalidation_0-logloss:0.32256\n",
      "[82]\tvalidation_0-logloss:0.32260\n",
      "[83]\tvalidation_0-logloss:0.32246\n",
      "[84]\tvalidation_0-logloss:0.32241\n",
      "[85]\tvalidation_0-logloss:0.32245\n",
      "[86]\tvalidation_0-logloss:0.32245\n",
      "[87]\tvalidation_0-logloss:0.32249\n",
      "[88]\tvalidation_0-logloss:0.32255\n",
      "[89]\tvalidation_0-logloss:0.32263\n",
      "[90]\tvalidation_0-logloss:0.32262\n",
      "[91]\tvalidation_0-logloss:0.32262\n",
      "[92]\tvalidation_0-logloss:0.32250\n",
      "[93]\tvalidation_0-logloss:0.32253\n",
      "[94]\tvalidation_0-logloss:0.32245\n",
      "[95]\tvalidation_0-logloss:0.32240\n",
      "[96]\tvalidation_0-logloss:0.32240\n",
      "[97]\tvalidation_0-logloss:0.32241\n",
      "[98]\tvalidation_0-logloss:0.32232\n",
      "[99]\tvalidation_0-logloss:0.32227\n"
     ]
    }
   ],
   "source": [
    "# Define XGBoost model with regularization\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,  # To avoid a warning message in newer versions\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    n_estimators=100,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_split, y_train_split,\n",
    "    eval_set=[(X_val_split, y_val_split)]\n",
    ")\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]  # Probability of the positive class\n",
    "\n",
    "# Create a DataFrame for final scores\n",
    "FinalScores = pd.DataFrame({'article_id': test.iloc[:, 59].astype('int32'), 'score': y_pred_proba})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "FinalScores.to_csv('XGBoost_output_proba_regularized.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
